{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a digit classification ML model on the mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all neccesary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Nvida GPU as device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "print(device) # check wether gpu was found\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DataSet Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.x, self.y = torch.load(filepath)\n",
    "        \n",
    "        # Normalizing the values to [0,1]\n",
    "        self.x = self.x / 255. \n",
    "        \n",
    "        # One Hot Encoding the class labels as they are nominal:\n",
    "        self.y = F.one_hot(self.y, num_classes=10).to(float) \n",
    "        \n",
    "    def __len__(self): \n",
    "        return self.x.shape[0]\n",
    "    def __getitem__(self, i): \n",
    "        return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Training Set and Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MyDataset('MNIST/processed/training.pt')\n",
    "test_set = MyDataset('MNIST/processed/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size = 784, hidden_size = 500, num_classes = 10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, model, num_epochs, learning_rate):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "    \n",
    "    # Track loss and performance metrics across epochs\n",
    "    epoch_losses = []\n",
    "    epoch_precisions = []\n",
    "    epoch_recalls = []\n",
    "    epoch_f1s = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "    \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "    \n",
    "        # Calculate performance metrics for the epoch\n",
    "        precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "        recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    \n",
    "        epoch_precisions.append(precision)\n",
    "        epoch_recalls.append(recall)\n",
    "        epoch_f1s.append(f1)\n",
    "    \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'trained_models/nn.pth')\n",
    "    print('Finished Training')\n",
    "    print()\n",
    "    print('Hyperparameters used for training:')\n",
    "    print(f'Number of Epochs: {num_epochs}, Batch Size: {batch_size}, learning rate: {learning_rate}')\n",
    "    print()\n",
    "\n",
    "# Note: Ensure 'device' and 'batch_size' are defined before calling this function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Loss: 0.0004, Precision: 0.9999, Recall: 0.9999, F1-Score: 0.9999\n",
      "Epoch [2/12], Loss: 0.0001, Precision: 0.9999, Recall: 0.9999, F1-Score: 0.9999\n",
      "Epoch [3/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [4/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [5/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [6/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [7/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [8/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [9/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [10/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [11/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Epoch [12/12], Loss: 0.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
      "Finished Training\n",
      "\n",
      "Hyperparameters used for training:\n",
      "Number of Epochs: 12, Batch Size: 100, learning rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(training_loader, model, num_epochs = 12, learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 98.54%\n",
      "Precision: 0.9853\n",
      "Recall: 0.9853\n",
      "F1-Score: 0.9853\n",
      "Confusion Matrix:\n",
      "[[ 974    1    1    0    0    1    1    1    1    0]\n",
      " [   0 1128    2    1    0    0    1    1    2    0]\n",
      " [   1    1 1014    3    3    0    2    2    6    0]\n",
      " [   1    0    4  998    0    3    0    1    2    1]\n",
      " [   1    0    2    0  966    0    4    0    0    9]\n",
      " [   2    0    1    8    1  876    2    1    1    0]\n",
      " [   3    2    0    1    3    2  946    0    1    0]\n",
      " [   1    2    5    1    0    0    0 1013    2    4]\n",
      " [   3    0    3    3    2    2    1    3  953    4]\n",
      " [   0    2    0    3    9    3    0    3    3  986]]\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * (np.array(all_predictions) == np.array(all_labels)).sum() / len(all_labels)\n",
    "precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "# Optionally, print the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudatorch",
   "language": "python",
   "name": "cudatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
